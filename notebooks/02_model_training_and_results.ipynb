{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1151c2",
   "metadata": {},
   "source": [
    "## Construction of Basic Models and Classification\n",
    "\n",
    "The main task was binary classification (predicting the occurrence of the disease). The training process proceeded as follows:\n",
    "* **Preprocessing:** Applied *One-Hot Encoding* for categorical variables and standardization (*StandardScaler*) for numerical variables.\n",
    "* **Data Split:** Training set (80%) and Test set (20%) with stratification.\n",
    "* **Model:** Initially, Logistic Regression and Random Forest were used.\n",
    "\n",
    "### Model Performance Comparison\n",
    "\n",
    "An evaluation of two models was conducted: Random Forest and Logistic Regression. The table below presents a comparison of key quality metrics (for the positive class 1 - Diabetic).\n",
    "\n",
    "| Metric | Random Forest (RF) | Logistic Regression (LR) |\n",
    "| :--- | :---: | :---: |\n",
    "| **Accuracy** | **0.901** | 0.894 |\n",
    "| **ROC AUC** | **0.948** | 0.942 |\n",
    "| **Precision (Class 1)** | **0.867** | 0.866 |\n",
    "| **Recall (Class 1)** | **0.797** | 0.770 |\n",
    "| **F1-Score (Class 1)** | **0.830** | 0.815 |\n",
    "\n",
    "The **Random Forest** model achieved slightly better results across all key indicators.\n",
    "\n",
    "### Detailed Classification Report\n",
    "\n",
    "| Model | Class | Precision | Recall | F1-Score |\n",
    "| :--- | :---: | :---: | :---: | :---: |\n",
    "| **Random Forest** | 0 (Healthy) | 0.91 | 0.95 | 0.93 |\n",
    "| | 1 (Diabetic) | 0.87 | 0.80 | 0.83 |\n",
    "| **Logistic Regression** | 0 (Healthy) | 0.90 | 0.95 | 0.93 |\n",
    "| | 1 (Diabetic) | 0.87 | 0.77 | 0.82 |\n",
    "\n",
    "---\n",
    "\n",
    "## Experiments and Training Process Optimization\n",
    "\n",
    "To achieve the highest possible predictive model quality, a series of experiments were conducted to examine the impact of preprocessing, feature selection, and validation strategies on the final results.\n",
    "\n",
    "### Threshold Tuning\n",
    "\n",
    "In medical diagnostics, the standard threshold of 0.5 is often not optimal because the cost of missing a disease (False Negative) is higher than the cost of a false alarm. An analysis was conducted for the standard threshold of **0.5** and a lowered threshold of **0.3**.\n",
    "\n",
    "| Threshold | Accuracy | Precision | Recall | F1-Score |\n",
    "| :---: | :---: | :---: | :---: | :---: |\n",
    "| 0.5 | **0.905** | **0.874** | 0.801 | **0.836** |\n",
    "| **0.3** | 0.890 | 0.782 | **0.881** | 0.829 |\n",
    "\n",
    "**Conclusion:** Lowering the threshold to **0.3** allowed for an increase in sensitivity (Recall) to **88.1%**, which is crucial in a medical decision support system.\n",
    "\n",
    "### Strategy for Handling Errors in Categorical Data\n",
    "\n",
    "Two strategies were tested for fixing invalid values in the `smoking` and `drinking` columns:\n",
    "1.  **DROP:** Removing rows with invalid values.\n",
    "2.  **CLIP:** Clipping values to the allowed range.\n",
    "\n",
    "| Strategy | Accuracy | Precision | Recall | ROC AUC |\n",
    "| :--- | :---: | :---: | :---: | :---: |\n",
    "| DROP | **0.925** | 0.667 | 0.771 | 0.948 |\n",
    "| **CLIP** | 0.890 | **0.782** | **0.881** | **0.955** |\n",
    "\n",
    "**Conclusion:** The **CLIP** strategy was chosen because the DROP strategy drastically reduced the model's sensitivity.\n",
    "\n",
    "### Impact of Removing Outliers\n",
    "\n",
    "The impact of removing anomalies detected using the IQR method was examined.\n",
    "\n",
    "| Dataset | Accuracy | Recall | F1-Score | ROC AUC |\n",
    "| :--- | :---: | :---: | :---: | :---: |\n",
    "| Full (With Outliers) | 0.890 | **0.881** | **0.816** | **0.944** |\n",
    "| Without Outliers | **0.894** | 0.588 | 0.603 | 0.891 |\n",
    "\n",
    "**Conclusion:** Removing outliers led to a drastic drop in Recall (from 87.7% to 58.8%). A decision was made **not to remove** anomalies, as extreme values likely represent strong predictors of the disease.\n",
    "\n",
    "### Feature Selection\n",
    "\n",
    "| Feature Set | Accuracy | Recall | F1-Score | ROC AUC |\n",
    "| :--- | :---: | :---: | :---: | :---: |\n",
    "| All Features | 0.890 | 0.881 | 0.828 | 0.954 |\n",
    "| Top 15 Features | 0.887 | 0.885 | 0.826 | 0.954 |\n",
    "| Top 9 Features | 0.882 | 0.877 | 0.817 | 0.946 |\n",
    "| Top 6 Features | 0.880 | 0.877 | 0.816 | 0.944 |\n",
    "\n",
    "**Conclusion:** It was decided to keep **all features** to maintain the maximum ROC AUC value.\n",
    "\n",
    "---\n",
    "\n",
    "## Model Tuning and Validation Strategy\n",
    "\n",
    "### Hyperparameter Optimization\n",
    "\n",
    "* `n_estimators`: 300\n",
    "* `max_depth`: 20\n",
    "* `class_weight`: 'balanced' (impact was negligible)\n",
    "\n",
    "### Validation: Hold-out vs. Cross-Validation\n",
    "\n",
    "| Validation Method | Recall | Std Dev | Precision | ROC AUC |\n",
    "| :--- | :---: | :---: | :---: | :---: |\n",
    "| Hold-out (Thr=0.3) | **0.881** | - | 0.774 | 0.955 |\n",
    "| Hold-out (Thr=0.5) | 0.813 | - | 0.909 | 0.955 |\n",
    "| 5-Fold CV (Thr=0.5) | 0.824 | +/- 0.022 | **0.886** | **0.963** |\n",
    "\n",
    "The results confirm model stability and lack of overfitting (Hold-out results are close to the CV average).\n",
    "\n",
    "### Final Results - Model Card\n",
    "\n",
    "| Parameter / Metric | Value / Description |\n",
    "| :--- | :--- |\n",
    "| **Model** | **Random Forest** |\n",
    "| Number of Trees | 300 |\n",
    "| Max Depth | 20 |\n",
    "| Threshold | **0.3** |\n",
    "| **Data Strategy** | |\n",
    "| Categorical Fix | CLIP |\n",
    "| Outliers | Kept (Not removed) |\n",
    "| Features | All (18) |\n",
    "| **Results (Test Set)** | |\n",
    "| **Recall (Sensitivity)** | **0.881** |\n",
    "| Precision | 0.782 |\n",
    "| F1-Score | 0.829 |\n",
    "| Accuracy | 0.890 |\n",
    "| ROC AUC | 0.955 |\n",
    "\n",
    "## Final Summary\n",
    "\n",
    "The final **Random Forest** model is characterized by high diagnostic effectiveness:\n",
    "* Achieved **ROC AUC at the level of ~0.95**.\n",
    "* **Sensitivity (Recall) was maximized to approx. 88%**, which means high effectiveness in detecting sick patients.\n",
    "* It was identified that aggressive data cleaning (removing anomalies) is detrimental to model quality in this specific medical problem."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
